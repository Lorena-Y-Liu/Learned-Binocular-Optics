# Learned Binocular-Encoding Optics for RGBD Imaging

Official PyTorch implementation of **"Learned binocular-encoding optics for RGBD imaging using joint stereo and focus cues"**.

ðŸŒ **[Project Page](https://liangxunou.github.io/25liulearned/)** | ðŸ“„ **[Paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Learned_Binocular-Encoding_Optics_for_RGBD_Imaging_Using_Joint_Stereo_and_CVPR_2025_paper.pdf)** | ðŸ’» **[Code](https://github.com/Lorena-Y-Liu/Learned-Binocular-Optics)** | ðŸ“’ **[Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Liu_Learned_Binocular-Encoding_Optics_CVPR_2025_supplemental.pdf)**

## Overview

This project implements a novel RGBD imaging system that combines:
- **Diffractive Optical Elements (DOE)**: Learnable phase masks for depth-dependent Point Spread Functions (PSF)
- **Stereo Vision**: Learned binocular camera setup for RGB imaging and disparity-based depth estimation
- **Joint Optimization**: End-to-end training of both optical elements and neural network components

![Teaser](docs/teaser.png)

## News

- **[2025.06]** Paper accepted to CVPR 2025 as **Oral Paper**
- **[2025.11]** Code released

## Project Structure

```
deep_stereo/
â”œâ”€â”€ config.py               # Configuration system with dataclasses
â”œâ”€â”€ deepstereo.py           # Main PyTorch Lightning training module
â”œâ”€â”€ deepstereo_trainer.py   # Training script with data loading
â”œâ”€â”€ configs/                # YAML configuration files
â”‚   â””â”€â”€ config.yaml         # Default configuration
â”œâ”€â”€ optics/                 # DOE camera simulation modules
â”‚   â”œâ”€â”€ base_camera.py      # Base camera class with shared functionality
â”‚   â”œâ”€â”€ camera_left_rank1.py   # Left camera with Rank-1 DOE
â”‚   â”œâ”€â”€ camera_right_rank1.py  # Right camera with Rank-1 DOE
â”‚   â”œâ”€â”€ camera_left_rank2.py   # Left camera with Rank-2 DOE
â”‚   â”œâ”€â”€ camera_right_rank2.py  # Right camera with Rank-2 DOE
â”‚   â”œâ”€â”€ camera_left_ring.py    # Left camera with Ring DOE
â”‚   â””â”€â”€ camera_right_ring.py   # Right camera with Ring DOE
â”œâ”€â”€ core/                   # Core stereo matching components (IGEV-based)
â”‚   â”œâ”€â”€ igev_stereo.py      # IGEV stereo matching network
â”‚   â”œâ”€â”€ extractor.py        # Feature extraction
â”‚   â”œâ”€â”€ geometry.py         # Geometric operations
â”‚   â”œâ”€â”€ submodule.py        # Common submodules
â”‚   â””â”€â”€ update.py           # Iterative update modules
â”œâ”€â”€ models/                 # Neural network models
â”‚   â”œâ”€â”€ fusion.py           # Image recovery network
â”‚   â”œâ”€â”€ feature_fusion.py   # Feature fusion modules
â”‚   â”œâ”€â”€ outputs_container.py # Output data container
â”‚   â”œâ”€â”€ submodule.py        # Common submodules
â”‚   â””â”€â”€ unet.py             # U-Net architecture
â”œâ”€â”€ ls_asm/                 # Least-Sampling Angular Spectrum Method
â”‚   â”œâ”€â”€ LSASM.py            # Light propagation simulation
â”‚   â”œâ”€â”€ input_field.py      # Input field generation
â”‚   â”œâ”€â”€ phase_plates.py     # Phase plate definitions
â”‚   â””â”€â”€ utils.py            # LS-ASM utilities
â”œâ”€â”€ util/                   # Utility functions
â”œâ”€â”€ datasets/               # Dataset loaders
â”œâ”€â”€ solvers/                # Image reconstruction solvers
â”œâ”€â”€ psf/                    # PSF data and utilities
â”œâ”€â”€ doe_vector/             # Pre-trained DOE parameters
â””â”€â”€ examples/               # Usage examples
```

## DOE Types

The project supports three types of Diffractive Optical Elements:

| Type | Parameterization | Description |
|------|------------------|-------------|
| **Rank-1** | `h(x,y) = y * x^T` | Minimal parameters, simple depth-varying PSFs |
| **Rank-2** | `h(x,y) = yâ‚€ * xâ‚€^T + yâ‚ * xâ‚^T` | More expressive, good balance |
| **Ring** | Radially symmetric | Rotationally invariant PSFs |

## Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/deep_stereo.git
cd deep_stereo

# Create conda environment
conda create -n deep_stereo python=3.8
conda activate deep_stereo

# Install dependencies
pip install -r requirements.txt
```

### Dependencies
- PyTorch >= 1.9
- PyTorch Lightning
- torchvision
- OpenCV
- numpy
- scipy
- PyYAML
- kornia

## Quick Start

### Training

```bash
# Run training with default config
python deepstereo_trainer.py

# Or specify a config file
python deepstereo_trainer.py --config configs/config.yaml
```

### Inference

```bash
# Run inference on captured images
python run_captured.py --checkpoint path/to/checkpoint.ckpt
```

## Configuration

Edit `configs/config.yaml` to modify parameters:

```yaml
# Experiment settings
experiment_name: deep_stereo_training

# Optical system parameters
optics:
  doe_type: rank2           # Options: rank1, rank2, ring
  use_pretrained_doe: false
  focal_depth: 1.23         # meters

# Training parameters
training:
  batch_sz: 2
  cnn_lr: 0.001
  max_epochs: 100
```

## Camera Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| Focal length | 35mm | Camera focal length |
| Sensor pitch | 5.86Î¼m | Camera sensor pixel size |
| Mask size | 1260 | DOE mask resolution |
| Wavelengths | 632nm, 550nm, 450nm | RGB wavelengths |

## Citation

If you find this code useful for your research, please cite our paper:

```bibtex
@inproceedings{liu2025learned,
  title={Learned Binocular-Encoding Optics for RGBD Imaging Using Joint Stereo and Focus Cues},
  author={Liu, Yuhui and Ou, Liangxun and Fu, Qiang and Amata, Hadi and Heidrich, Wolfgang and Peng, Yifan},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={15833--15842},
  year={2025}
}
```

## Acknowledgments

This project builds upon several excellent open-source works:

- **[Depth from Defocus with Learned Optics](https://github.com/computational-imaging/DepthFromDefocusWithLearnedOptics)** - DOE optimization and depth-from-defocus framework
- **[ASASM (Adaptive Sampling Angular Spectrum Method)](https://github.com/whywww/ASASM)** - Wave propagation simulation
- **[IGEV-Stereo](https://github.com/gangweix/IGEV)** - Iterative geometry encoding stereo matching network

We thank the authors for releasing their code.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Contact

For questions or issues, please open an issue on GitHub or contact us via the [project page](https://liangxunou.github.io/25liulearned/).
